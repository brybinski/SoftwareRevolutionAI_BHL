{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install shap\n",
    "# %pip install lime\n",
    "#%pip install scikit-learn==1.3.2\n",
    "\n",
    "# %pip install xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryba/Documents/Code/snek/SoftwareRevolutionAI_BHL/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/ryba/Documents/Code/snek/SoftwareRevolutionAI_BHL/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność modelu Random Forest: 0.45911477869467365\n",
      "Dokładność modelu XGBoost: 0.4973743435858965\n",
      "Dokładność modelu Gradient Boosting: 0.5123780945236309\n",
      "Dokładność modelu SVM: 0.4816204051012753\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Wczytanie danych\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Usunięcie brakujących wartości\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# One-Hot Encoding dla kolumny 'Profession'\n",
    "profession_encoder = OneHotEncoder(sparse=False)\n",
    "profession_encoded = profession_encoder.fit_transform(data[['Profession']])\n",
    "profession_df = pd.DataFrame(profession_encoded, columns=profession_encoder.get_feature_names_out(['Profession']))\n",
    "data = pd.concat([data.drop(['Profession'], axis=1), profession_df], axis=1)\n",
    "\n",
    "# One-Hot Encoding dla kolumny 'Var_1'\n",
    "var_1_encoder = OneHotEncoder(sparse=False)\n",
    "var_1_encoded = var_1_encoder.fit_transform(data[['Var_1']])\n",
    "var_1_df = pd.DataFrame(var_1_encoded, columns=var_1_encoder.get_feature_names_out(['Var_1']))\n",
    "data = pd.concat([data.drop(['Var_1'], axis=1), var_1_df], axis=1)\n",
    "\n",
    "# Label Encoding dla kolumn kategorycznych\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['Gender', 'Ever_Married', 'Graduated', 'Spending_Score', 'Segmentation']\n",
    "for col in categorical_columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X = data.drop(['Segmentation', 'ID', 'Age'], axis=1)\n",
    "y = data['Segmentation']\n",
    "\n",
    "cols_X = X.columns\n",
    "scaler = MinMaxScaler()\n",
    "X= scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Skalowanie danych\n",
    "\n",
    "\n",
    "################################################################3\n",
    "# Inicjalizacja i dopasowanie modelu Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Ocena modelu\n",
    "y_pred = model_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Dokładność modelu Random Forest:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(objective='multi:softmax', num_class=4, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Przewidywanie klas dla danych testowych\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Obliczenie dokładności modelu\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Dokładność modelu XGBoost:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "#########################################3\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicjalizacja klasyfikatora Gradient Boosting\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Dopasowanie modelu do danych treningowych\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Przewidywanie klas dla danych testowych\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "# Obliczenie dokładności modelu\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Dokładność modelu Gradient Boosting:\", accuracy_gb)\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicjalizacja klasyfikatora SVM\n",
    "svm_clf = SVC(kernel='linear', decision_function_shape='ovr', random_state=42)\n",
    "\n",
    "# Dopasowanie modelu do danych treningowych\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Przewidywanie klas dla danych testowych\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Obliczenie dokładności modelu\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Dokładność modelu SVM:\", accuracy_svm)\n",
    "\n",
    "\n",
    "######################################################\n",
    "export = pd.DataFrame(X_test, columns=cols_X)\n",
    "export['Seg'] = y\n",
    "export.to_csv('xddd.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (948363241.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    al.result['_label_'] = f'AL profiles{['a','b','c','d'][i]}'\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# POTEM, jesli w ogole\n",
    "import numpy as np\n",
    "import dalex as dx\n",
    "result_shap = []\n",
    "idx_X = np.random.randint(low=0, high=len(X_test), size=10)\n",
    "\n",
    "for i in range(0,4):\n",
    "    result_shap.append([])\n",
    "    pf = lambda m, d: m.predict_proba(d)[:, i]\n",
    "    exp = dx.Explainer(gb_clf, pd.DataFrame(X_test, columns=cols_X), y_test,  predict_function=pf)\n",
    "\n",
    "    for j in range(len(idx_X)):\n",
    "        result_shap[i].append(exp.predict_parts(X_test[idx_X[j]], N=10, type=\"shap\").result)\n",
    "\n",
    "    # Debug plots\n",
    "    # ins_exp.plot()\n",
    "    # exp.model_parts().plot()\n",
    "    # ld.result\n",
    "    al = exp.model_profile(type = 'accumulated')\n",
    "    al.result['_label_'] = f'AL profiles{['a','b','c','d'][i]}'\n",
    "    al.plot()\n",
    "    exp.model_diagnostics().plot()\n",
    "print(result_shap)\n",
    "\n",
    "warnings.filterwarnings(\"default\", category=UserWarning)\n",
    "warnings.filterwarnings(\"default\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1333 rows 22 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1333 values\n",
      "  -> model_class       : sklearn.ensemble._gb.GradientBoostingClassifier (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function calculate_shap.<locals>.<lambda> at 0x7fdcd8993c40> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.0169, mean = 0.242, max = 0.729\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.729, mean = 1.34, max = 2.98\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1333 rows 22 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1333 values\n",
      "  -> model_class       : sklearn.ensemble._gb.GradientBoostingClassifier (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function calculate_shap.<locals>.<lambda> at 0x7fdcd892e520> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.0128, mean = 0.236, max = 0.769\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.666, mean = 1.34, max = 2.99\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1333 rows 22 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1333 values\n",
      "  -> model_class       : sklearn.ensemble._gb.GradientBoostingClassifier (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function calculate_shap.<locals>.<lambda> at 0x7fdcd8993c40> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.00645, mean = 0.262, max = 0.9\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.788, mean = 1.32, max = 2.99\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 1333 rows 22 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 1333 values\n",
      "  -> model_class       : sklearn.ensemble._gb.GradientBoostingClassifier (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function calculate_shap.<locals>.<lambda> at 0x7fdcdcc14f40> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.00639, mean = 0.261, max = 0.944\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.909, mean = 1.32, max = 2.98\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>contribution</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>sign</th>\n",
       "      <th>label</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Profession_Engineer = 0.0</td>\n",
       "      <td>-0.005527</td>\n",
       "      <td>Profession_Engineer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var_1_Cat_4 = 0.0</td>\n",
       "      <td>-0.004465</td>\n",
       "      <td>Var_1_Cat_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Profession_Artist = 0.0</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>Profession_Artist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var_1_Cat_3 = 1.0</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>Var_1_Cat_3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Profession_Lawyer = 0.0</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>Profession_Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spending_Score = 1.0</td>\n",
       "      <td>-0.000586</td>\n",
       "      <td>Spending_Score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Profession_Lawyer = 0.0</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>Profession_Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var_1_Cat_1 = 0.0</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>Var_1_Cat_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var_1_Cat_5 = 0.0</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>Var_1_Cat_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var_1_Cat_7 = 0.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>Var_1_Cat_7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable  contribution        variable_name  \\\n",
       "0   Profession_Engineer = 0.0     -0.005527  Profession_Engineer   \n",
       "1           Var_1_Cat_4 = 0.0     -0.004465          Var_1_Cat_4   \n",
       "2     Profession_Artist = 0.0      0.015823    Profession_Artist   \n",
       "3           Var_1_Cat_3 = 1.0      0.015538          Var_1_Cat_3   \n",
       "4     Profession_Lawyer = 0.0     -0.002081    Profession_Lawyer   \n",
       "..                        ...           ...                  ...   \n",
       "17       Spending_Score = 1.0     -0.000586       Spending_Score   \n",
       "18    Profession_Lawyer = 0.0     -0.000402    Profession_Lawyer   \n",
       "19          Var_1_Cat_1 = 0.0      0.000361          Var_1_Cat_1   \n",
       "20          Var_1_Cat_5 = 0.0     -0.000155          Var_1_Cat_5   \n",
       "21          Var_1_Cat_7 = 0.0      0.000043          Var_1_Cat_7   \n",
       "\n",
       "    variable_value  sign                       label  B  \n",
       "0              0.0  -1.0  GradientBoostingClassifier  1  \n",
       "1              0.0  -1.0  GradientBoostingClassifier  1  \n",
       "2              0.0   1.0  GradientBoostingClassifier  1  \n",
       "3              1.0   1.0  GradientBoostingClassifier  1  \n",
       "4              0.0  -1.0  GradientBoostingClassifier  1  \n",
       "..             ...   ...                         ... ..  \n",
       "17             1.0  -1.0  GradientBoostingClassifier  0  \n",
       "18             0.0  -1.0  GradientBoostingClassifier  0  \n",
       "19             0.0   1.0  GradientBoostingClassifier  0  \n",
       "20             0.0  -1.0  GradientBoostingClassifier  0  \n",
       "21             0.0   1.0  GradientBoostingClassifier  0  \n",
       "\n",
       "[572 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install statsmodels\n",
    "# %pip install dalex\n",
    "\n",
    "import dalex as dx\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "def calculate_shap(model, X, y, instance, cls_num, N=1000):\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "    result = []\n",
    "    for i in range(0, cls_num):\n",
    "        \n",
    "        pf = lambda m, d: m.predict_proba(d)[:, i]\n",
    "        exp = dx.Explainer(model, X, y,  predict_function=pf)\n",
    "        result.append(exp.predict_parts(instance, type=\"shap\").result)\n",
    "    warnings.filterwarnings(\"default\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"default\", category=FutureWarning)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Sprawdzanie \n",
    "res = calculate_shap(gb_clf, pd.DataFrame(X_test, columns=cols_X), y_test, X_test[0], 4)\n",
    "res[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
